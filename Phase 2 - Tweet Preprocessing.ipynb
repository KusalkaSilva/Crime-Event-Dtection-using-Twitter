{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041689dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kusalkasilva/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kusalkasilva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kusalkasilva/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "import spacy\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf6f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv file\n",
    "tweet_df = pd.read_csv(\"Tweet_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b24172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 247007 entries, 0 to 247006\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   author id   247007 non-null  object\n",
      " 1   created_at  247007 non-null  object\n",
      " 2   geo         247007 non-null  object\n",
      " 3   id          247007 non-null  object\n",
      " 4   language    247007 non-null  object\n",
      " 5   source      247007 non-null  object\n",
      " 6   tweet       247007 non-null  object\n",
      " 7   location    247007 non-null  object\n",
      " 8   bbox        247007 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check stats - no null values\n",
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21e7413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing hashing\n",
    "tweet_df[\"clean_tweet\"] = None\n",
    "\n",
    "for i in range(len(tweet_df)):\n",
    "    tweet_df['clean_tweet'][i] = tweet_df['tweet'][i].replace(\"#\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4fecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text-Cleaning (URLs, Mentions,etc, non alphabet characters, but noticed that full stops, question marks weren't removed) \n",
    "#- cleaning is done using tweet-preprocessor package\n",
    "\n",
    "for i in range(len(tweet_df)):\n",
    "    tweet_df['clean_tweet'][i] = p.clean(tweet_df['tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be01dfae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205824</th>\n",
       "      <td>@EuropaLeague braga the local police are the b...</td>\n",
       "      <td>braga the local police are the biggest bunch o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241851</th>\n",
       "      <td>@SergeantCustard @AmazonUK THANK YOU. I bet it...</td>\n",
       "      <td>THANK YOU. I bet it's a tough book to read jus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "205824  @EuropaLeague braga the local police are the b...   \n",
       "241851  @SergeantCustard @AmazonUK THANK YOU. I bet it...   \n",
       "\n",
       "                                              clean_tweet  \n",
       "205824  braga the local police are the biggest bunch o...  \n",
       "241851  THANK YOU. I bet it's a tough book to read jus...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output\n",
    "tweet_df[['tweet','clean_tweet']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f30e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering using regex\n",
    "for i in range (len(tweet_df['clean_tweet'])):\n",
    "    tweet_df['clean_tweet'][i] = re.sub(r\"(@[A-Za-z0-9_]+)|[^\\w\\s]|#|http\\S+\", \"\", tweet_df['clean_tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a87fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201279</th>\n",
       "      <td>@bmj_latest @TheBMA @NHSEmployers @AoMRC @theR...</td>\n",
       "      <td>Theres no excuse but how about you examine Cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29789</th>\n",
       "      <td>Great watching @SocialistTelly tonight with @0...</td>\n",
       "      <td>Great watching tonight with and  Really good a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "201279  @bmj_latest @TheBMA @NHSEmployers @AoMRC @theR...   \n",
       "29789   Great watching @SocialistTelly tonight with @0...   \n",
       "\n",
       "                                              clean_tweet  \n",
       "201279  Theres no excuse but how about you examine Cau...  \n",
       "29789   Great watching tonight with and  Really good a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[['tweet','clean_tweet']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678b41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercasing\n",
    "lower_text = tweet_df['clean_tweet'].str.lower()\n",
    "tweet_df['clean_tweet'] = lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc235eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74913</th>\n",
       "      <td>@rmorganbentley \"HOW TO MURDER YOUR WIFE AND G...</td>\n",
       "      <td>how to murder your wife and get away with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133583</th>\n",
       "      <td>Double homicide https://t.co/tmNkDt2WoC</td>\n",
       "      <td>double homicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "74913   @rmorganbentley \"HOW TO MURDER YOUR WIFE AND G...   \n",
       "133583            Double homicide https://t.co/tmNkDt2WoC   \n",
       "\n",
       "                                       clean_tweet  \n",
       "74913   how to murder your wife and get away with   \n",
       "133583                             double homicide  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[['tweet','clean_tweet']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc77b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "w_tokenizer =  TweetTokenizer()\n",
    "\n",
    "# Lemmatization using spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tweet_df[\"lemmatized_tweet\"] = lower_text.apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))\n",
    "tweet_df['lemmatized_tweet'] = tweet_df['lemmatized_tweet'].apply(w_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fece7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "w_tokenizer =  TweetTokenizer()\n",
    " \n",
    "def stem_text(text):\n",
    "    return [(stemmer.stem(w)) for w \\\n",
    "                       in w_tokenizer.tokenize((text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28701361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying function stemming\n",
    "tweet_df['stemming_tweet'] = lower_text.apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2aee3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>lemmatized_tweet</th>\n",
       "      <th>stemming_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35671</th>\n",
       "      <td>12/02/21 #LateShift Marked Proactive Patrols o...</td>\n",
       "      <td>0221 marked proactive patrols of between atten...</td>\n",
       "      <td>[0221, mark, proactive, patrol, of, between, a...</td>\n",
       "      <td>[0221, mark, proactiv, patrol, of, between, at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135105</th>\n",
       "      <td>@SonnyBunch Respectfully disagree. We're const...</td>\n",
       "      <td>respectfully disagree were constantly invited ...</td>\n",
       "      <td>[respectfully, disagree, be, constantly, invit...</td>\n",
       "      <td>[respect, disagre, were, constant, invit, to, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "35671   12/02/21 #LateShift Marked Proactive Patrols o...   \n",
       "135105  @SonnyBunch Respectfully disagree. We're const...   \n",
       "\n",
       "                                              clean_tweet  \\\n",
       "35671   0221 marked proactive patrols of between atten...   \n",
       "135105  respectfully disagree were constantly invited ...   \n",
       "\n",
       "                                         lemmatized_tweet  \\\n",
       "35671   [0221, mark, proactive, patrol, of, between, a...   \n",
       "135105  [respectfully, disagree, be, constantly, invit...   \n",
       "\n",
       "                                           stemming_tweet  \n",
       "35671   [0221, mark, proactiv, patrol, of, between, at...  \n",
       "135105  [respect, disagre, were, constant, invit, to, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[['tweet', 'clean_tweet', 'lemmatized_tweet', 'stemming_tweet']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b1d27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stopwords dictionary in english language \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c5c0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we exclude not from the stopwords corpus since removing not from the text will change the context of the text\n",
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110d8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words removal\n",
    "tweet_df['clean_tweet_lem'] = None\n",
    "tweet_df['clean_tweet_stem'] = None\n",
    "\n",
    "for i in range(len(tweet_df)):\n",
    "    tweet_df['lemmatized_tweet'][i] = [word for word in tweet_df['lemmatized_tweet'][i] if not word in stop_words]\n",
    "    \n",
    "    tweet_df['stemming_tweet'][i] = [word for word in tweet_df['stemming_tweet'][i] if not word in stop_words]\n",
    "    \n",
    "    tweet_df['clean_tweet_lem'][i] = [word for word in tweet_df['lemmatized_tweet'][i] if not word in stop_words]\n",
    "    tweet_df['clean_tweet_lem'][i] = (\" \").join([word for word in tweet_df['lemmatized_tweet'][i] if not word in stop_words])\n",
    "    \n",
    "    tweet_df['clean_tweet_stem'][i] = [word for word in tweet_df['stemming_tweet'][i] if not word in stop_words]\n",
    "    tweet_df['clean_tweet_stem'][i] = (\" \").join([word for word in tweet_df['stemming_tweet'][i] if not word in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ca5f25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>lemmatized_tweet</th>\n",
       "      <th>stemming_tweet</th>\n",
       "      <th>clean_tweet_lem</th>\n",
       "      <th>clean_tweet_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140723</th>\n",
       "      <td>The best! \\r\\nhttps://t.co/oiuL7VWV7E</td>\n",
       "      <td>the best</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[best]</td>\n",
       "      <td>good</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22075</th>\n",
       "      <td>@DJISupport  ,just bought new machine,charged ...</td>\n",
       "      <td>just bought new machinecharged batteries to di...</td>\n",
       "      <td>[buy, new, machinecharge, battery, not, fly, h...</td>\n",
       "      <td>[bought, new, machinecharg, batteri, didnt, fl...</td>\n",
       "      <td>buy new machinecharge battery not fly house ba...</td>\n",
       "      <td>bought new machinecharg batteri didnt fli hous...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "140723              The best! \\r\\nhttps://t.co/oiuL7VWV7E   \n",
       "22075   @DJISupport  ,just bought new machine,charged ...   \n",
       "\n",
       "                                              clean_tweet  \\\n",
       "140723                                           the best   \n",
       "22075   just bought new machinecharged batteries to di...   \n",
       "\n",
       "                                         lemmatized_tweet  \\\n",
       "140723                                             [good]   \n",
       "22075   [buy, new, machinecharge, battery, not, fly, h...   \n",
       "\n",
       "                                           stemming_tweet  \\\n",
       "140723                                             [best]   \n",
       "22075   [bought, new, machinecharg, batteri, didnt, fl...   \n",
       "\n",
       "                                          clean_tweet_lem  \\\n",
       "140723                                               good   \n",
       "22075   buy new machinecharge battery not fly house ba...   \n",
       "\n",
       "                                         clean_tweet_stem  \n",
       "140723                                               best  \n",
       "22075   bought new machinecharg batteri didnt fli hous...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[['tweet', 'clean_tweet', 'lemmatized_tweet', 'stemming_tweet', 'clean_tweet_lem', 'clean_tweet_stem']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e9ad027",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.drop(columns=\"clean_tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72668fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 247007 entries, 0 to 247006\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   author id         247007 non-null  object\n",
      " 1   created_at        247007 non-null  object\n",
      " 2   geo               247007 non-null  object\n",
      " 3   id                247007 non-null  object\n",
      " 4   language          247007 non-null  object\n",
      " 5   source            247007 non-null  object\n",
      " 6   tweet             247007 non-null  object\n",
      " 7   location          247007 non-null  object\n",
      " 8   bbox              247007 non-null  object\n",
      " 9   lemmatized_tweet  247007 non-null  object\n",
      " 10  stemming_tweet    247007 non-null  object\n",
      " 11  clean_tweet_lem   247007 non-null  object\n",
      " 12  clean_tweet_stem  247007 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 24.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#dataset columns summary\n",
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49e07f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicated tweets\n",
    "tweet_df.drop_duplicates(inplace=True, subset=\"clean_tweet_lem\")\n",
    "tweet_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e1fc6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234977 entries, 0 to 234976\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   index             234977 non-null  int64 \n",
      " 1   author id         234977 non-null  object\n",
      " 2   created_at        234977 non-null  object\n",
      " 3   geo               234977 non-null  object\n",
      " 4   id                234977 non-null  object\n",
      " 5   language          234977 non-null  object\n",
      " 6   source            234977 non-null  object\n",
      " 7   tweet             234977 non-null  object\n",
      " 8   location          234977 non-null  object\n",
      " 9   bbox              234977 non-null  object\n",
      " 10  lemmatized_tweet  234977 non-null  object\n",
      " 11  stemming_tweet    234977 non-null  object\n",
      " 12  clean_tweet_lem   234977 non-null  object\n",
      " 13  clean_tweet_stem  234977 non-null  object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 25.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa2be709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Length Filtering\n",
    "for i in range(len(tweet_df)):\n",
    "    if len(tweet_df['lemmatized_tweet'][i]) <= 2 :\n",
    "        tweet_df = tweet_df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b99e0c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 231460 entries, 0 to 234976\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   index             231460 non-null  int64 \n",
      " 1   author id         231460 non-null  object\n",
      " 2   created_at        231460 non-null  object\n",
      " 3   geo               231460 non-null  object\n",
      " 4   id                231460 non-null  object\n",
      " 5   language          231460 non-null  object\n",
      " 6   source            231460 non-null  object\n",
      " 7   tweet             231460 non-null  object\n",
      " 8   location          231460 non-null  object\n",
      " 9   bbox              231460 non-null  object\n",
      " 10  lemmatized_tweet  231460 non-null  object\n",
      " 11  stemming_tweet    231460 non-null  object\n",
      " 12  clean_tweet_lem   231460 non-null  object\n",
      " 13  clean_tweet_stem  231460 non-null  object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8937245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>lemmatized_tweet</th>\n",
       "      <th>stemming_tweet</th>\n",
       "      <th>clean_tweet_lem</th>\n",
       "      <th>clean_tweet_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180238</th>\n",
       "      <td>What is this Bastard us country\\nEngland \\nI. ...</td>\n",
       "      <td>[bastard, us, countryengland, I, like, lomborg...</td>\n",
       "      <td>[bastard, us, countryengland, like, lomborghin...</td>\n",
       "      <td>bastard us countryengland I like lomborghiniph...</td>\n",
       "      <td>bastard us countryengland like lomborghiniphot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29526</th>\n",
       "      <td>Did I imagine that Ghislaine Maxwell has been ...</td>\n",
       "      <td>[I, imagine, ghislaine, maxwell, convict, anyt...</td>\n",
       "      <td>[imagin, ghislain, maxwel, convict, anyth, yet...</td>\n",
       "      <td>I imagine ghislaine maxwell convict anything y...</td>\n",
       "      <td>imagin ghislain maxwel convict anyth yet didnt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "180238  What is this Bastard us country\\nEngland \\nI. ...   \n",
       "29526   Did I imagine that Ghislaine Maxwell has been ...   \n",
       "\n",
       "                                         lemmatized_tweet  \\\n",
       "180238  [bastard, us, countryengland, I, like, lomborg...   \n",
       "29526   [I, imagine, ghislaine, maxwell, convict, anyt...   \n",
       "\n",
       "                                           stemming_tweet  \\\n",
       "180238  [bastard, us, countryengland, like, lomborghin...   \n",
       "29526   [imagin, ghislain, maxwel, convict, anyth, yet...   \n",
       "\n",
       "                                          clean_tweet_lem  \\\n",
       "180238  bastard us countryengland I like lomborghiniph...   \n",
       "29526   I imagine ghislaine maxwell convict anything y...   \n",
       "\n",
       "                                         clean_tweet_stem  \n",
       "180238  bastard us countryengland like lomborghiniphot...  \n",
       "29526   imagin ghislain maxwel convict anyth yet didnt...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[['tweet', 'lemmatized_tweet', 'stemming_tweet', 'clean_tweet_lem', 'clean_tweet_stem']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e171b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save csv\n",
    "tweet_df.to_csv('HashingPreprocessed_Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668c1f4",
   "metadata": {},
   "source": [
    "<h2>References - </h2>\n",
    "\n",
    "https://towardsdatascience.com/basic-tweet-preprocessing-in-python-efd8360d529e\n",
    "https://aronakhmad.medium.com/twitter-data-cleaning-using-python-db1ec2f28f08\n",
    "https://towardsai.net/p/programming/tweet-topic-modeling-part-2-cleaning-and-preprocessing-tweets\n",
    "https://www.linkedin.com/pulse/extracting-twitter-data-pre-processing-sentiment-using-jayasekara/\n",
    "https://stackabuse.com/removing-stop-words-from-strings-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
